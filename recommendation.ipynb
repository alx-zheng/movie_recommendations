{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d099587e-397b-4953-8e1e-b93dfc7fe34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(cp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2a00c-da8f-4e94-bb07-1ef88a2a5499",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df460ff-4c03-4a49-9a09-51648afebfbd",
   "metadata": {},
   "source": [
    "**Parsing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cc6fb8-f498-4189-921d-05a1b358b308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"mat_comp_small\"\n",
    "filename = \"mat_comp\"\n",
    "n, m, k = 0, 0, 0\n",
    "\n",
    "f = open(filename, \"r\")\n",
    "n, m, k = map(int, f.readline().strip().split(\" \"))\n",
    "f.close()\n",
    "\n",
    "ratings = pd.read_csv(filename, delimiter=\" \",skiprows=1, nrows=k, names=[\"i\", \"j\", \"rating\"])\n",
    "q = pd.read_csv(filename, delimiter=\" \",skiprows=k+1, nrows=1, names=[\"1\"])[\"1\"][0]\n",
    "queries = pd.read_csv(filename, delimiter=\" \",skiprows=k+2, nrows=q, names=[\"i\", \"j\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d96e7c-8667-4ddf-a3ae-6f2d101097ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(queries)\n",
    "print(ratings)\n",
    "ratings.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "890c483f",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa49bb4-a875-4ef6-af20-fec7abd2a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ratings[[\"i\", \"j\"]], ratings[\"rating\"], test_size=0.2, random_state=49)\n",
    "X_test = np.asarray(X_test)\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train).reshape(-1, 1)\n",
    "y_test = np.asarray(y_train).reshape(-1, 1)\n",
    "\n",
    "print(np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))\n",
    "print(X_test[:5])\n",
    "print(y_test[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f76359e",
   "metadata": {},
   "source": [
    "**Constructing M**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3545691d-8f81-4bfc-9f0b-0c496623e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.zeros([n, m], dtype=float)\n",
    "for indices, rating in zip(X_train, y_train):\n",
    "    M[indices[0]-1][indices[1]-1] = rating\n",
    "print(f\"M = \\n{M}\\nM_shape = {np.shape(M)}\\n\\n\")\n",
    "print(n, m)\n",
    "print(f\"Queries = \\n{queries}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1dba30f",
   "metadata": {},
   "source": [
    "**Initializations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff1427b-7fee-4173-83be-10ff890d5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SVD Initializations\"\"\"\n",
    "U, singular_values, V = np.linalg.svd(M, full_matrices=False)\n",
    "S = np.zeros((np.shape(U)[1], np.shape(V)[0]))\n",
    "np.fill_diagonal(S, singular_values)\n",
    "X1, Y1 = U@S, V\n",
    "# print(f\"U shape: {np.shape(U)}\")\n",
    "# print(f\"S shape: {np.shape(S)}\")\n",
    "# print(f\"V shape: {np.shape(V)}\")\n",
    "# print(f\"X1 shape: {np.shape(X1)}\")\n",
    "# print(f\"Y1 shape: {np.shape(Y1)}\")\n",
    "\n",
    "r = 15\n",
    "MAX_ITERS = 30\n",
    "lr = 0.001\n",
    "X_init = np.random.uniform(0, 5, (m, r))\n",
    "M_input = M.transpose()\n",
    "\n",
    "print(np.shape(X_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ffa16a-a2ea-4677-af0a-b2506452a765",
   "metadata": {},
   "source": [
    "**Alternating Minimizaiton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e819ac-c0d8-4eb1-bcc9-2c84521081b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternating_minimization(M, r, max_iter, X_init):\n",
    "    X, Y = X_init, None\n",
    "    residual = np.zeros(MAX_ITERS)\n",
    "    for iter_num in range(1, max_iter + 1):\n",
    "        # For odd iterations, treat X constant, optimize over Y.\n",
    "        if iter_num % 2 == 1:\n",
    "            Y = cp.Variable(shape=(r, n))\n",
    "            constraint = [Y >= 0, Y <= 3]\n",
    "        # For even iterations, treat Y constant, optimize over X.\n",
    "        else:\n",
    "            X = cp.Variable(shape=(m, r))\n",
    "            constraint = [X >= 0, X <= 3]\n",
    "            \n",
    "        obj = cp.Minimize(cp.norm(M - X@Y, 'fro'))\n",
    "        prob = cp.Problem(obj, constraint)\n",
    "        prob.solve(solver=cp.SCS, max_iters=5000)\n",
    "        \n",
    "        if prob.status != cp.OPTIMAL:\n",
    "            raise Exception(\"Solver did not converge!\")\n",
    "        \n",
    "        print('Iteration {}, residual norm: {}'.format(iter_num, round(prob.value, 2)))\n",
    "        residual[iter_num-1] = prob.value\n",
    "\n",
    "        # Convert variable to NumPy array constant for next iteration.\n",
    "        if iter_num % 2 == 1:\n",
    "            Y = Y.value\n",
    "        else:\n",
    "            X = X.value\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1749d35-3a2b-4b19-b91d-658a88b9968e",
   "metadata": {},
   "source": [
    "**Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d5c76e-58da-4b0d-84e1-1fdeae2127aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(M, X_init, Y_init, lr = 0.001, iterations=10000):\n",
    "    \"\"\"\n",
    "    Gradient Descent 1: This approach did not work because the in the loss funciton,\n",
    "    the M we used represented empty results as 0s. This caused gradient descent\n",
    "    to optimize the indices of the queries to 0. Therefore this approach does not\n",
    "    work.\n",
    "    \"\"\"\n",
    "    X, Y = X_init, Y_init\n",
    "    cur_M = X @ Y.T\n",
    "    for i in range(iterations):\n",
    "        if i % 1000 == 0: print(f\"{round((i / iterations) * 100, 2)}% complete \\n {cur_M}\")\n",
    "        X -= lr * (-2 * (M - X@Y.T) @ Y)\n",
    "        Y -= lr * (-2 * (M.T - Y@X.T) @ X)\n",
    "        cur_M = X @ Y.T\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc82c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent2(M, X_init, Y_init, nonzeros, lr = 0.001, iterations=10000):\n",
    "    \"\"\"\n",
    "    Gradient Descent 2: This approach seeks to optimize using a more granular view\n",
    "    to the matrices X and Y. The loss is approximately to minimize M - X@Y\n",
    "    \"\"\"\n",
    "    X, Y = X_init, Y_init\n",
    "    ii, jj = nonzeros\n",
    "    ii -= 1\n",
    "    jj -= 1\n",
    "    for epoch in range(iterations):\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch: {epoch}\")\n",
    "            print(f\"cur_m\\n: {X@Y}\\n\")\n",
    "            print(f\"cur_m[0][3]: {(X@Y)[0][3]}\\n\")\n",
    "        for i, j in zip(ii,jj):\n",
    "            e_ij = M[i][j] - np.dot(X[i,:], Y[:,j])\n",
    "            grad_X = -2 * e_ij * Y[:,j]\n",
    "            grad_Y = -2 * e_ij * X[i,:]\n",
    "            X[i,:] -= lr * grad_X\n",
    "            Y[:,j] -= lr * grad_Y\n",
    "    return X, Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36bb591e-1642-40d7-abba-36ab0feb8d90",
   "metadata": {},
   "source": [
    "**Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f984999-661b-493f-ac9b-b69e5d43d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loss(X_test, y_test, predict_m, verbose=False):\n",
    "    \"\"\"\n",
    "    predicted_m: nxm ndarray containing recommendation predictions for indices in X_test. y_test contains ground truth ratings\n",
    "    \"\"\"\n",
    "    squared_error = 0\n",
    "    S = len(X_test)\n",
    "    for indices, true in zip(X_test, y_test):\n",
    "        if verbose: print(f\"true: {true[0]} predicted: {round(predict_m[indices[0]-1][indices[1]-1], 2)}\")\n",
    "        squared_error += (true[0] - predict_m[indices[0]-1][indices[1]-1]) ** 2\n",
    "\n",
    "    loss = (1/S) * squared_error\n",
    "    print(f\"loss: {loss}\")\n",
    "    print(f\"grade: {min(4, max(0, 4*(1.8 - loss)))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5527a42",
   "metadata": {},
   "source": [
    "**Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21627b-3287-4411-8a5e-b02d06465034",
   "metadata": {},
   "outputs": [],
   "source": [
    "xinit, yinit = np.random.uniform(0, 0.7, (n, r)), np.random.uniform(0, 0.7, (m, r))\n",
    "X_descent, Y_descent = gradient_descent(M, xinit, yinit, learning_rate=lr, iterations=80000)\n",
    "gradient_descent_M1 = X_descent@Y_descent.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c94a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize X, Y, and nonzero indices\n",
    "xinit, yinit = np.random.uniform(0, 0.7, (n, r)), np.random.uniform(0, 0.7, (r, m))\n",
    "nonzero_indices = M.nonzero()\n",
    "\n",
    "X_descent2, Y_descent2 = gradient_descent2(M, xinit, yinit, nonzero_indices, lr=lr, iterations=5000)\n",
    "gradient_descent_M2 = X_descent2@Y_descent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5efc36a-137b-4c2f-95f1-1e843de5f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testing Loss for Gradient Descents\"\"\"\n",
    "test_loss(X_test, y_test, gradient_descent_M2, verbose=True) #gd2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60ecdb58",
   "metadata": {},
   "source": [
    "**Alternating Minimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86533ab7-c567-48f2-a74e-c58c4d27b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Alternating Minimization\"\"\"\n",
    "X_alter, Y_alter = alternating_minimization(M_input, r, MAX_ITERS, X_init)\n",
    "alternating_minimization_M = (X_alter@Y_alter).transpose() #transposing because in alternaitng minimization, X@Y results in M_transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fe31c-d357-4947-897e-7bb141b12004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Testing Loss for Alternating Minimization\"\"\"\n",
    "test_loss(X_test, y_test, alternating_minimization_M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9b2dd-8e3a-4c39-a82f-5ad43253503c",
   "metadata": {},
   "source": [
    "**SKLEARN NMF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c11db-c944-45ae-8072-5f9dfbbe7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=7, init='random', random_state=2, max_iter=10000, beta_loss=2)\n",
    "W = model.fit_transform(M)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ecbe6-dc9e-4aae-91c3-a616af76c3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_nmf_M = W@H\n",
    "print(np.shape(sklearn_nmf_M))\n",
    "\n",
    "scale = lambda t: t * 5 if (t * 3.5 < 4.5) else t\n",
    "vscale = np.vectorize(scale)\n",
    "m = vscale(sklearn_nmf_M)\n",
    "\n",
    "test_loss(X_test, y_test, sklearn_nmf_M)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "795c5231",
   "metadata": {},
   "source": [
    "**Uniform LOL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fdf327-1502-437e-8a81-85ac92196d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform3 = np.random.uniform(3.3, 3.3, np.shape(M))\n",
    "test_loss(X_test, y_test, uniform3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c4a87-e0c5-421a-9f71-0297330db6d9",
   "metadata": {},
   "source": [
    "**Final Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d0a15-9079-4c92-9aef-c5dc7497e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(m_pred):    \n",
    "    query_prediction = np.zeros(len(queries.index))\n",
    "    with open(\"./mat_comp_ans\", \"w\") as file:\n",
    "        for index, row in queries.iterrows():\n",
    "            file.write(str(3.3) + \"\\n\")\n",
    "            # query_prediction[index] = m_pred[row['i']-1][row['j']-1]\n",
    "    print(len(queries))\n",
    "\n",
    "make_predictions(uniform3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
